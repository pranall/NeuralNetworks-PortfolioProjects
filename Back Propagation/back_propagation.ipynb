{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbyn46_btMiT",
        "outputId": "088b04f6-fd1c-4876-c1f5-fe6a91586a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load nn.py\n",
        "\"\"\"nn\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1PzWci5sVAxAE9ZAeDPLhatxxUCrnUfiG\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"nn.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from scipy.special import expit  # Sigmoid function\n",
        "\n",
        "class SimpleNetwork:\n",
        "    \"\"\"A simple feedforward network where all units have sigmoid activation.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def random(cls, *layer_units: int):\n",
        "        \"\"\"Creates a feedforward neural network with the given number of units\n",
        "        for each layer.\n",
        "\n",
        "        :param layer_units: Number of units for each layer\n",
        "        :return: the neural network\n",
        "        \"\"\"\n",
        "\n",
        "        def uniform(n_in, n_out):\n",
        "            epsilon = math.sqrt(6) / math.sqrt(n_in + n_out)\n",
        "            return np.random.uniform(-epsilon, +epsilon, size=(n_in, n_out))\n",
        "\n",
        "        pairs = zip(layer_units, layer_units[1:])\n",
        "        return cls(*[uniform(i, o) for i, o in pairs])\n",
        "\n",
        "    def __init__(self, *layer_weights: np.ndarray):\n",
        "        \"\"\"Creates a neural network from a list of weight matrices.\n",
        "        The weights correspond to transformations from one layer to the next, so\n",
        "        the number of layers is equal to one more than the number of weight\n",
        "        matrices.\n",
        "\n",
        "        :param layer_weights: A list of weight matrices\n",
        "        \"\"\"\n",
        "        self.weights = list(layer_weights)\n",
        "\n",
        "    def predict(self, input_matrix: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Performs forward propagation over the neural network starting with\n",
        "        the given input matrix.\n",
        "\n",
        "        Each unit's output should be calculated by taking a weighted sum of its\n",
        "        inputs (using the appropriate weight matrix) and passing the result of\n",
        "        that sum through a logistic sigmoid activation function.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :return: A matrix of predictions, where each row is the predicted\n",
        "        outputs - each in the range (0, 1) - for the corresponding row in the\n",
        "        input matrix.\n",
        "        \"\"\"\n",
        "        h = input_matrix\n",
        "        for weight in self.weights:\n",
        "            h = expit(np.dot(h, weight))\n",
        "        return h\n",
        "\n",
        "    def predict_zero_one(self, input_matrix: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Performs forward propagation over the neural network starting with\n",
        "        the given input matrix, and converts the outputs to binary (0 or 1).\n",
        "\n",
        "        Outputs will be converted to 0 if they are less than 0.5, and converted\n",
        "        to 1 otherwise.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :return: A matrix of predictions, where each row is the predicted\n",
        "        outputs - each either 0 or 1 - for the corresponding row in the input\n",
        "        matrix.\n",
        "        \"\"\"\n",
        "        predictions = self.predict(input_matrix)\n",
        "        return np.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "    def gradients(self,\n",
        "                  input_matrix: np.ndarray,\n",
        "                  output_matrix: np.ndarray) -> List[np.ndarray]:\n",
        "        \"\"\"Performs back-propagation to calculate the gradients for each of\n",
        "        the weight matrices.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :param output_matrix: A matrix of expected outputs, where each row is\n",
        "        the expected outputs - each either 0 or 1 - for the corresponding row in\n",
        "        the input matrix.\n",
        "        :return: the gradient matrix for each weight matrix\n",
        "        \"\"\"\n",
        "        # Forward pass\n",
        "        activations = [input_matrix]\n",
        "        a_list = []\n",
        "        h = input_matrix\n",
        "        for weight in self.weights:\n",
        "            a = np.dot(h, weight)\n",
        "            a_list.append(a)\n",
        "            h = expit(a)\n",
        "            activations.append(h)\n",
        "\n",
        "        # Backward pass\n",
        "        gradients = []\n",
        "        error = activations[-1] - output_matrix\n",
        "        for l in range(len(self.weights) - 1, -1, -1):\n",
        "            g = error * activations[l + 1] * (1 - activations[l + 1])\n",
        "            grad = np.dot(activations[l].T, g) / input_matrix.shape[0]\n",
        "            gradients.append(grad)\n",
        "            if l > 0:\n",
        "                error = np.dot(g, self.weights[l].T)\n",
        "\n",
        "        gradients.reverse()\n",
        "        return gradients\n",
        "\n",
        "    def train(self,\n",
        "              input_matrix: np.ndarray,\n",
        "              output_matrix: np.ndarray,\n",
        "              iterations: int = 10,\n",
        "              learning_rate: float = 0.1) -> None:\n",
        "        \"\"\"Trains the neural network on an input matrix and an expected output\n",
        "        matrix.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :param output_matrix: A matrix of expected outputs, where each row is\n",
        "        the expected outputs - each either 0 or 1 - for the corresponding row in\n",
        "        the input matrix.\n",
        "        :param iterations: The number of gradient descent steps to take.\n",
        "        :param learning_rate: The size of gradient descent steps to take, a\n",
        "        number that the gradients should be multiplied by before updating the\n",
        "        model weights.\n",
        "        \"\"\"\n",
        "        for _ in range(iterations):\n",
        "            gradients = self.gradients(input_matrix, output_matrix)\n",
        "            for i in range(len(self.weights)):\n",
        "                self.weights[i] -= learning_rate * gradients[i]"
      ],
      "metadata": {
        "id": "vj3BVPTVtSSX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('nn.py', 'r') as file:\n",
        "    code = file.read()"
      ],
      "metadata": {
        "id": "uKyPvSeWtT_h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXTCBvItVyf",
        "outputId": "c29248ac-3fe5-4c11-ea24-89eb288053a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"nn\n",
            "\n",
            "Automatically generated by Colab.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1PzWci5sVAxAE9ZAeDPLhatxxUCrnUfiG\n",
            "\"\"\"\n",
            "\n",
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"nn.ipynb\n",
            "\n",
            "Automatically generated by Colaboratory.\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "import math\n",
            "from typing import List\n",
            "\n",
            "import numpy as np\n",
            "from scipy.special import expit  # Sigmoid function\n",
            "\n",
            "class SimpleNetwork:\n",
            "    \"\"\"A simple feedforward network where all units have sigmoid activation.\n",
            "    \"\"\"\n",
            "\n",
            "    @classmethod\n",
            "    def random(cls, *layer_units: int):\n",
            "        \"\"\"Creates a feedforward neural network with the given number of units\n",
            "        for each layer.\n",
            "\n",
            "        :param layer_units: Number of units for each layer\n",
            "        :return: the neural network\n",
            "        \"\"\"\n",
            "\n",
            "        def uniform(n_in, n_out):\n",
            "            epsilon = math.sqrt(6) / math.sqrt(n_in + n_out)\n",
            "            return np.random.uniform(-epsilon, +epsilon, size=(n_in, n_out))\n",
            "\n",
            "        pairs = zip(layer_units, layer_units[1:])\n",
            "        return cls(*[uniform(i, o) for i, o in pairs])\n",
            "\n",
            "    def __init__(self, *layer_weights: np.ndarray):\n",
            "        \"\"\"Creates a neural network from a list of weight matrices.\n",
            "        The weights correspond to transformations from one layer to the next, so\n",
            "        the number of layers is equal to one more than the number of weight\n",
            "        matrices.\n",
            "\n",
            "        :param layer_weights: A list of weight matrices\n",
            "        \"\"\"\n",
            "        self.weights = list(layer_weights)\n",
            "\n",
            "    def predict(self, input_matrix: np.ndarray) -> np.ndarray:\n",
            "        \"\"\"Performs forward propagation over the neural network starting with\n",
            "        the given input matrix.\n",
            "\n",
            "        Each unit's output should be calculated by taking a weighted sum of its\n",
            "        inputs (using the appropriate weight matrix) and passing the result of\n",
            "        that sum through a logistic sigmoid activation function.\n",
            "\n",
            "        :param input_matrix: The matrix of inputs to the network, where each\n",
            "        row in the matrix represents an instance for which the neural network\n",
            "        should make a prediction\n",
            "        :return: A matrix of predictions, where each row is the predicted\n",
            "        outputs - each in the range (0, 1) - for the corresponding row in the\n",
            "        input matrix.\n",
            "        \"\"\"\n",
            "        h = input_matrix\n",
            "        for weight in self.weights:\n",
            "            h = expit(np.dot(h, weight))\n",
            "        return h\n",
            "\n",
            "    def predict_zero_one(self, input_matrix: np.ndarray) -> np.ndarray:\n",
            "        \"\"\"Performs forward propagation over the neural network starting with\n",
            "        the given input matrix, and converts the outputs to binary (0 or 1).\n",
            "\n",
            "        Outputs will be converted to 0 if they are less than 0.5, and converted\n",
            "        to 1 otherwise.\n",
            "\n",
            "        :param input_matrix: The matrix of inputs to the network, where each\n",
            "        row in the matrix represents an instance for which the neural network\n",
            "        should make a prediction\n",
            "        :return: A matrix of predictions, where each row is the predicted\n",
            "        outputs - each either 0 or 1 - for the corresponding row in the input\n",
            "        matrix.\n",
            "        \"\"\"\n",
            "        predictions = self.predict(input_matrix)\n",
            "        return np.where(predictions < 0.5, 0, 1)\n",
            "\n",
            "    def gradients(self,\n",
            "                  input_matrix: np.ndarray,\n",
            "                  output_matrix: np.ndarray) -> List[np.ndarray]:\n",
            "        \"\"\"Performs back-propagation to calculate the gradients for each of\n",
            "        the weight matrices.\n",
            "\n",
            "        :param input_matrix: The matrix of inputs to the network, where each\n",
            "        row in the matrix represents an instance for which the neural network\n",
            "        should make a prediction\n",
            "        :param output_matrix: A matrix of expected outputs, where each row is\n",
            "        the expected outputs - each either 0 or 1 - for the corresponding row in\n",
            "        the input matrix.\n",
            "        :return: the gradient matrix for each weight matrix\n",
            "        \"\"\"\n",
            "        # Forward pass\n",
            "        activations = [input_matrix]\n",
            "        a_list = []\n",
            "        h = input_matrix\n",
            "        for weight in self.weights:\n",
            "            a = np.dot(h, weight)\n",
            "            a_list.append(a)\n",
            "            h = expit(a)\n",
            "            activations.append(h)\n",
            "\n",
            "        # Backward pass\n",
            "        gradients = []\n",
            "        error = activations[-1] - output_matrix\n",
            "        for l in range(len(self.weights) - 1, -1, -1):\n",
            "            g = error * activations[l + 1] * (1 - activations[l + 1])\n",
            "            grad = np.dot(activations[l].T, g) / input_matrix.shape[0]\n",
            "            gradients.append(grad)\n",
            "            if l > 0:\n",
            "                error = np.dot(g, self.weights[l].T)\n",
            "\n",
            "        gradients.reverse()\n",
            "        return gradients\n",
            "\n",
            "    def train(self,\n",
            "              input_matrix: np.ndarray,\n",
            "              output_matrix: np.ndarray,\n",
            "              iterations: int = 10,\n",
            "              learning_rate: float = 0.1) -> None:\n",
            "        \"\"\"Trains the neural network on an input matrix and an expected output\n",
            "        matrix.\n",
            "\n",
            "        :param input_matrix: The matrix of inputs to the network, where each\n",
            "        row in the matrix represents an instance for which the neural network\n",
            "        should make a prediction\n",
            "        :param output_matrix: A matrix of expected outputs, where each row is\n",
            "        the expected outputs - each either 0 or 1 - for the corresponding row in\n",
            "        the input matrix.\n",
            "        :param iterations: The number of gradient descent steps to take.\n",
            "        :param learning_rate: The size of gradient descent steps to take, a\n",
            "        number that the gradients should be multiplied by before updating the\n",
            "        model weights.\n",
            "        \"\"\"\n",
            "        for _ in range(iterations):\n",
            "            gradients = self.gradients(input_matrix, output_matrix)\n",
            "            for i in range(len(self.weights)):\n",
            "                self.weights[i] -= learning_rate * gradients[i]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load test_nn.py\n",
        "\"\"\"test_nn\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1bbYMedBgr6lw0butpwFJ2FSKYJWQ3d1L\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"test_nn.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1mGHNhilHEMqcWpR53TUAvZyVt6TpgfkS\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pytest\n",
        "\n",
        "import nn\n",
        "\n",
        "\n",
        "\n",
        "def set_seed():\n",
        "    np.random.seed(42)\n",
        "\n",
        "\n",
        "\n",
        "def test_predict():\n",
        "    net = nn.SimpleNetwork(np.array([[.1, -.2],\n",
        "                                     [-.3, .4],\n",
        "                                     [.5, -.6]]),\n",
        "                           np.array([[-.7, .8, -.9],\n",
        "                                     [.10, -.11, .12]]))\n",
        "    input_matrix = np.array([[13, -14, 15],\n",
        "                             [-16, 17, -18]])\n",
        "    predictions = net.predict(input_matrix)\n",
        "    [[h11, h12],\n",
        "     [h21, h22]] = [[s(13 * .1 + -14 * -.3 + 15 * .5),\n",
        "                     s(13 * -.2 + -14 * .4 + 15 * -.6)],\n",
        "                    [s(-16 * .1 + 17 * -.3 - 18 * .5),\n",
        "                     s(-16 * -.2 + 17 * .4 + -18 * -.6)]]\n",
        "    np.testing.assert_allclose(predictions, np.array(\n",
        "        [[s(h11 * -.7 + h12 * .10),\n",
        "          s(h11 * .8 + h12 * -.11),\n",
        "          s(h11 * -.9 + h12 * .12)],\n",
        "         [s(h21 * -.7 + h22 * .10),\n",
        "          s(h21 * .8 + h22 * -.11),\n",
        "          s(h21 * -.9 + h22 * .12)]]))\n",
        "\n",
        "    binary_predictions = net.predict_zero_one(input_matrix)\n",
        "    np.testing.assert_array_equal(binary_predictions, np.array([[0, 1, 0],\n",
        "                                                                [1, 0, 1]]))\n",
        "\n",
        "\n",
        "\n",
        "def test_gradients():\n",
        "    net = nn.SimpleNetwork(np.array([[.1, .3, .5],\n",
        "                                     [-.5, -.3, -.1]]),\n",
        "                           np.array([[.2, -.2],\n",
        "                                     [.4, -.4],\n",
        "                                     [.6, -.6]]))\n",
        "    input_matrix = np.array([[0, 0],\n",
        "                             [1, 0],\n",
        "                             [0, 1],\n",
        "                             [1, 1]])\n",
        "    output_matrix = np.array([[1, 1],\n",
        "                              [0, 1],\n",
        "                              [1, 0],\n",
        "                              [0, 0]])\n",
        "    [[hi11, hi12, hi13],\n",
        "     [hi21, hi22, hi23],\n",
        "     [hi31, hi32, hi33],\n",
        "     [hi41, hi42, hi43]] = hi = [\n",
        "        [.1 * 0 + -.5 * 0, .3 * 0 + -.3 * 0, .5 * 0 + -.1 * 0],\n",
        "        [.1 * 1 + -.5 * 0, .3 * 1 + -.3 * 0, .5 * 1 + -.1 * 0],\n",
        "        [.1 * 0 + -.5 * 1, .3 * 0 + -.3 * 1, .5 * 0 + -.1 * 1],\n",
        "        [.1 * 1 + -.5 * 1, .3 * 1 + -.3 * 1, .5 * 1 + -.1 * 1]]\n",
        "    [[h11, h12, h13],\n",
        "     [h21, h22, h23],\n",
        "     [h31, h32, h33],\n",
        "     [h41, h42, h43]] = [[s(x) for x in row] for row in hi]\n",
        "    [[oi11, oi12],\n",
        "     [oi21, oi22],\n",
        "     [oi31, oi32],\n",
        "     [oi41, oi42]] = oi = [\n",
        "        [h11 * .2 + h12 * .4 + h13 * .6, h11 * -.2 + h12 * -.4 + h13 * -.6],\n",
        "        [h21 * .2 + h22 * .4 + h23 * .6, h21 * -.2 + h22 * -.4 + h23 * -.6],\n",
        "        [h31 * .2 + h32 * .4 + h33 * .6, h31 * -.2 + h32 * -.4 + h33 * -.6],\n",
        "        [h41 * .2 + h42 * .4 + h43 * .6, h41 * -.2 + h42 * -.4 + h43 * -.6]]\n",
        "    [[o11, o12],\n",
        "     [o21, o22],\n",
        "     [o31, o32],\n",
        "     [o41, o42]] = [[s(x) for x in row] for row in oi]\n",
        "    [[do11, do12],\n",
        "     [do21, do22],\n",
        "     [do31, do32],\n",
        "     [do41, do42]] = [[(o11 - 1) * sg(oi11), (o12 - 1) * sg(oi12)],\n",
        "                      [(o21 - 0) * sg(oi21), (o22 - 1) * sg(oi22)],\n",
        "                      [(o31 - 1) * sg(oi31), (o32 - 0) * sg(oi32)],\n",
        "                      [(o41 - 0) * sg(oi41), (o42 - 0) * sg(oi42)]]\n",
        "    [[dh11, dh12, dh13],\n",
        "     [dh21, dh22, dh23],\n",
        "     [dh31, dh32, dh33],\n",
        "     [dh41, dh42, dh43]] = [[(.2 * do11 + -.2 * do12) * sg(hi11),\n",
        "                             (.4 * do11 + -.4 * do12) * sg(hi12),\n",
        "                             (.6 * do11 + -.6 * do12) * sg(hi13)],\n",
        "                            [(.2 * do21 + -.2 * do22) * sg(hi21),\n",
        "                             (.4 * do21 + -.4 * do22) * sg(hi22),\n",
        "                             (.6 * do21 + -.6 * do22) * sg(hi23)],\n",
        "                            [(.2 * do31 + -.2 * do32) * sg(hi31),\n",
        "                             (.4 * do31 + -.4 * do32) * sg(hi32),\n",
        "                             (.6 * do31 + -.6 * do32) * sg(hi33)],\n",
        "                            [(.2 * do41 + -.2 * do42) * sg(hi41),\n",
        "                             (.4 * do41 + -.4 * do42) * sg(hi42),\n",
        "                             (.6 * do41 + -.6 * do42) * sg(hi43)]]\n",
        "\n",
        "    [input_to_hidden_gradient,\n",
        "     hidden_to_output_gradient] = net.gradients(input_matrix, output_matrix)\n",
        "\n",
        "    np.testing.assert_allclose(hidden_to_output_gradient, np.array(\n",
        "        [[(do11 * h11 + do21 * h21 + do31 * h31 + do41 * h41) / 4,\n",
        "          (do12 * h11 + do22 * h21 + do32 * h31 + do42 * h41) / 4],\n",
        "         [(do11 * h12 + do21 * h22 + do31 * h32 + do41 * h42) / 4,\n",
        "          (do12 * h12 + do22 * h22 + do32 * h32 + do42 * h42) / 4],\n",
        "         [(do11 * h13 + do21 * h23 + do31 * h33 + do41 * h43) / 4,\n",
        "          (do12 * h13 + do22 * h23 + do32 * h33 + do42 * h43) / 4]]))\n",
        "\n",
        "    np.testing.assert_allclose(input_to_hidden_gradient, np.array(\n",
        "        [[(0 * dh11 + 1 * dh21 + 0 * dh31 + 1 * dh41) / 4,\n",
        "          (0 * dh12 + 1 * dh22 + 0 * dh32 + 1 * dh42) / 4,\n",
        "          (0 * dh13 + 1 * dh23 + 0 * dh33 + 1 * dh43) / 4],\n",
        "         [(0 * dh11 + 0 * dh21 + 1 * dh31 + 1 * dh41) / 4,\n",
        "          (0 * dh12 + 0 * dh22 + 1 * dh32 + 1 * dh42) / 4,\n",
        "          (0 * dh13 + 0 * dh23 + 1 * dh33 + 1 * dh43) / 4]]))\n",
        "\n",
        "\n",
        "\n",
        "def test_train_greater_than_half():\n",
        "    inputs = np.random.uniform(size=(100, 1))\n",
        "    outputs = (inputs > 0.5).astype(int)\n",
        "\n",
        "    net = nn.SimpleNetwork.random(1, 5, 5, 1)\n",
        "    assert len(net.gradients(inputs, outputs)) == 3\n",
        "    net.train(inputs, outputs, iterations=1000, learning_rate=1)\n",
        "\n",
        "    test_inputs = np.array([[0.0], [0.1], [0.2], [0.3], [0.4],\n",
        "                            [0.6], [0.7], [0.8], [0.9], [1.0]])\n",
        "    test_outputs = np.array([[0], [0], [0], [0], [0],\n",
        "                             [1], [1], [1], [1], [1]])\n",
        "    assert (net.predict_zero_one(test_inputs) == test_outputs).sum() >= 9\n",
        "\n",
        "\n",
        "\n",
        "def test_train_xor():\n",
        "    inputs = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "    outputs = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "    net = nn.SimpleNetwork.random(3, 3, 1)\n",
        "    assert len(net.gradients(inputs, outputs)) == 2\n",
        "    net.train(inputs, outputs, iterations=5000, learning_rate=0.5)\n",
        "\n",
        "    assert np.all(net.predict_zero_one(inputs) == outputs)\n",
        "\n",
        "\n",
        "\n",
        "def test_train_learning_rate():\n",
        "    inputs = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "    outputs = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "    net = nn.SimpleNetwork.random(3, 3, 1)\n",
        "    net.train(inputs, outputs, iterations=5000, learning_rate=0.01)\n",
        "\n",
        "    assert np.sometrue(net.predict_zero_one(inputs) != outputs)\n",
        "\n",
        "    net = nn.SimpleNetwork.random(3, 3, 1)\n",
        "    net.train(inputs, outputs, iterations=5000, learning_rate=1)\n",
        "\n",
        "    assert np.all(net.predict_zero_one(inputs) == outputs)\n",
        "\n",
        "\n",
        "def s(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "\n",
        "def sg(x):\n",
        "    return s(x) * (1 - s(x))"
      ],
      "metadata": {
        "id": "IZ7pMrVftXRg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1ztnOLRtY25",
        "outputId": "71a479f2-eab4-4c77-84ba-e0bdb07388a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.11.11, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: typeguard-4.4.1, anyio-3.7.1, langsmith-0.3.5\n",
            "collected 5 items                                                                                  \u001b[0m\n",
            "\n",
            "test_nn.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                             [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 1.79s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}