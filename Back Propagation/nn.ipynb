{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aznCx4FCrfoP"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"nn.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from scipy.special import expit  # Sigmoid function\n",
        "\n",
        "class SimpleNetwork:\n",
        "    \"\"\"A simple feedforward network where all units have sigmoid activation.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def random(cls, *layer_units: int):\n",
        "        \"\"\"Creates a feedforward neural network with the given number of units\n",
        "        for each layer.\n",
        "\n",
        "        :param layer_units: Number of units for each layer\n",
        "        :return: the neural network\n",
        "        \"\"\"\n",
        "\n",
        "        def uniform(n_in, n_out):\n",
        "            epsilon = math.sqrt(6) / math.sqrt(n_in + n_out)\n",
        "            return np.random.uniform(-epsilon, +epsilon, size=(n_in, n_out))\n",
        "\n",
        "        pairs = zip(layer_units, layer_units[1:])\n",
        "        return cls(*[uniform(i, o) for i, o in pairs])\n",
        "\n",
        "    def __init__(self, *layer_weights: np.ndarray):\n",
        "        \"\"\"Creates a neural network from a list of weight matrices.\n",
        "        The weights correspond to transformations from one layer to the next, so\n",
        "        the number of layers is equal to one more than the number of weight\n",
        "        matrices.\n",
        "\n",
        "        :param layer_weights: A list of weight matrices\n",
        "        \"\"\"\n",
        "        self.weights = list(layer_weights)\n",
        "\n",
        "    def predict(self, input_matrix: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Performs forward propagation over the neural network starting with\n",
        "        the given input matrix.\n",
        "\n",
        "        Each unit's output should be calculated by taking a weighted sum of its\n",
        "        inputs (using the appropriate weight matrix) and passing the result of\n",
        "        that sum through a logistic sigmoid activation function.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :return: A matrix of predictions, where each row is the predicted\n",
        "        outputs - each in the range (0, 1) - for the corresponding row in the\n",
        "        input matrix.\n",
        "        \"\"\"\n",
        "        h = input_matrix\n",
        "        for weight in self.weights:\n",
        "            h = expit(np.dot(h, weight))\n",
        "        return h\n",
        "\n",
        "    def predict_zero_one(self, input_matrix: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Performs forward propagation over the neural network starting with\n",
        "        the given input matrix, and converts the outputs to binary (0 or 1).\n",
        "\n",
        "        Outputs will be converted to 0 if they are less than 0.5, and converted\n",
        "        to 1 otherwise.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :return: A matrix of predictions, where each row is the predicted\n",
        "        outputs - each either 0 or 1 - for the corresponding row in the input\n",
        "        matrix.\n",
        "        \"\"\"\n",
        "        predictions = self.predict(input_matrix)\n",
        "        return np.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "    def gradients(self,\n",
        "                  input_matrix: np.ndarray,\n",
        "                  output_matrix: np.ndarray) -> List[np.ndarray]:\n",
        "        \"\"\"Performs back-propagation to calculate the gradients for each of\n",
        "        the weight matrices.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :param output_matrix: A matrix of expected outputs, where each row is\n",
        "        the expected outputs - each either 0 or 1 - for the corresponding row in\n",
        "        the input matrix.\n",
        "        :return: the gradient matrix for each weight matrix\n",
        "        \"\"\"\n",
        "        # Forward pass\n",
        "        activations = [input_matrix]\n",
        "        a_list = []\n",
        "        h = input_matrix\n",
        "        for weight in self.weights:\n",
        "            a = np.dot(h, weight)\n",
        "            a_list.append(a)\n",
        "            h = expit(a)\n",
        "            activations.append(h)\n",
        "\n",
        "        # Backward pass\n",
        "        gradients = []\n",
        "        error = activations[-1] - output_matrix\n",
        "        for l in range(len(self.weights) - 1, -1, -1):\n",
        "            g = error * activations[l + 1] * (1 - activations[l + 1])\n",
        "            grad = np.dot(activations[l].T, g) / input_matrix.shape[0]\n",
        "            gradients.append(grad)\n",
        "            if l > 0:\n",
        "                error = np.dot(g, self.weights[l].T)\n",
        "\n",
        "        gradients.reverse()\n",
        "        return gradients\n",
        "\n",
        "    def train(self,\n",
        "              input_matrix: np.ndarray,\n",
        "              output_matrix: np.ndarray,\n",
        "              iterations: int = 10,\n",
        "              learning_rate: float = 0.1) -> None:\n",
        "        \"\"\"Trains the neural network on an input matrix and an expected output\n",
        "        matrix.\n",
        "\n",
        "        :param input_matrix: The matrix of inputs to the network, where each\n",
        "        row in the matrix represents an instance for which the neural network\n",
        "        should make a prediction\n",
        "        :param output_matrix: A matrix of expected outputs, where each row is\n",
        "        the expected outputs - each either 0 or 1 - for the corresponding row in\n",
        "        the input matrix.\n",
        "        :param iterations: The number of gradient descent steps to take.\n",
        "        :param learning_rate: The size of gradient descent steps to take, a\n",
        "        number that the gradients should be multiplied by before updating the\n",
        "        model weights.\n",
        "        \"\"\"\n",
        "        for _ in range(iterations):\n",
        "            gradients = self.gradients(input_matrix, output_matrix)\n",
        "            for i in range(len(self.weights)):\n",
        "                self.weights[i] -= learning_rate * gradients[i]"
      ]
    }
  ]
}
